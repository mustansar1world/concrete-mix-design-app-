{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['F.A WA', 'F.A unit weight', 'WA average coarse',\n",
       "       'Average Unit weight coarse ', 'Cement', 'Fine Aggregate',\n",
       "       'Coarse Aggregate', 'Water', 'Slump', 'Strength 7days',\n",
       "       'Strength 28days', 'Size in mm', 'Cubical = 0/Cylindrical=1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cylindrical without admixture.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['F.A WA', 'F.A unit weight', 'WA average coarse',\n",
       "       'Average Unit weight coarse ', 'Slump', 'Strength 28days',\n",
       "       'Size in mm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Cement', 'Fine Aggregate',\n",
    "       'Coarse Aggregate', 'Water','Strength 7days','Cubical = 0/Cylindrical=1'],axis=1)\n",
    "y = df.drop(['F.A WA', 'F.A unit weight', 'WA average coarse','Average Unit weight coarse ','Cubical = 0/Cylindrical=1','Slump',\n",
    "       'Strength 28days', 'Size in mm'], axis=1)\n",
    "X.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Fine Aggregate', 'Coarse Aggregate', 'Water',\n",
       "       'Strength 7days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 7) (205, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.25, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_scaler = StandardScaler()\n",
    "xtrain_scaled = linear_scaler.fit_transform(xtrain)\n",
    "xtest_scaled = linear_scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, oob_score=True, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, oob_score=True, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=50, oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=50, random_state=0, oob_score=True)\n",
    "regressor.fit(xtrain_scaled,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9710796731699695\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(ytest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForest_model_97%_accuracy']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(regressor, \"RandomForest_model_97%_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cement  Fine Aggregate  Coarse Aggregate  Water  Strength 7days\n",
      "78      380             710              1060    213         2586.00\n",
      "97      375             725              1055    207         2597.00\n",
      "151     470             640              1070    231         3433.60\n",
      "44      350             710              1060    196         2183.00\n",
      "40      285             825               990    189         2037.25\n",
      "67      365             715              1060    202         2224.30\n",
      "98      340             680              1055    204         2673.00\n",
      "18      260             815              1010    162         1645.75\n",
      "152     475             660              1070    233         3397.00\n",
      "62      350             690              1090    190         2176.45\n",
      "4       260             785              1030    162         1509.45\n",
      "172     375             715              1055    210         2607.10\n",
      "197     470             640              1070    235         3455.35\n",
      "38      290             825               960    189         1924.15\n",
      "29      290             810               980    195         1890.80\n",
      "170     470             640              1070    235         3403.15\n",
      "190     450             640              1070    221         2975.40\n",
      "33      290             820               985    192         1929.95\n",
      "136     450             660              1070    216         2906.00\n",
      "145     430             665              1080    211         3077.00\n",
      "173     380             720              1055    209         2662.20\n",
      "31      295             820               980    195         1938.65\n",
      "11      265             825               990    173         1641.40\n",
      "119     380             685              1110    195         2704.00\n",
      "169     480             640              1075    255         3558.00\n",
      "34      290             820               985    192         1929.95\n",
      "84      375             705              1070    210         2614.00\n",
      "184     375             720              1060    207         2614.00\n",
      "120     380             725              1075    209         2654.95\n",
      "35      290             820               985    192         1929.95\n",
      "163     478             635              1058    234         3455.35\n",
      "28      285             810               990    192         1880.65\n",
      "16      270             810               980    181         1628.35\n",
      "130     445             640              1070    215         2911.00\n",
      "116     345             690              1060    207         2694.00\n",
      "182     475             645              1070    238         3389.00\n",
      "27      285             810               990    192         1880.65\n",
      "47      340             675              1100    181         2118.00\n",
      "58      355             720              1055    196         2222.85\n",
      "204     290             835               960    189         1977.80\n",
      "138     450             630              1080    218         2821.00\n",
      "106     340             680              1045    208         2671.00\n",
      "90      345             690              1050    207         2671.00\n",
      "147     465             640              1075    238         3155.00\n",
      "185     350             705              1065    196         2197.00\n",
      "95      375             720              1065    210         2640.45\n",
      "73      330             660              1045    198         2634.00\n",
      "51      350             705              1070    193         2173.00\n",
      "117     345             690              1060    207         2694.00\n",
      "103     375             710              1065    210         2623.05\n",
      "69      355             725              1075    196         2231.55\n",
      "107     380             725              1075    209         2654.95\n"
     ]
    }
   ],
   "source": [
    "print(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = linear_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = regressor.predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9877517501810905\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 252.9    800.2   1020.1    156.86  1435.844]\n",
      " [ 252.4    799.5   1021.2    155.96  1443.026]\n",
      " [ 253.2    808.3   1019.6    158.28  1469.608]\n",
      " ...\n",
      " [ 352.8    698.9   1046.5    206.28  2652.43 ]\n",
      " [ 270.     827.5    971.6    176.94  1611.588]\n",
      " [ 290.3    821.4    972.7    191.1   1936.649]]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('random_forest_predictions.csv', predict, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature 'Strength 28days': 0.9938453955663661\n",
      "2. Feature 'Slump': 0.0018926675085001936\n",
      "3. Feature 'F.A unit weight': 0.0013138828748972802\n",
      "4. Feature 'Average Unit weight coarse ': 0.001075245799030844\n",
      "5. Feature 'F.A WA': 0.0010377304075784482\n",
      "6. Feature 'WA average coarse': 0.0007641733645374417\n",
      "7. Feature 'Size in mm': 7.090447908974919e-05\n"
     ]
    }
   ],
   "source": [
    "#Taking the importance of the features \n",
    "feature_names = X.columns\n",
    "feature_importances = regressor.feature_importances_\n",
    "\n",
    "# Now, you can sort the feature importances and print them along with the feature names\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "for i, idx in enumerate(sorted_indices):\n",
    "    print(f\"{i+1}. Feature '{feature_names[idx]}': {feature_importances[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalyear",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
